apiVersion: batch/v1
kind: Job
metadata:
  name: alan-ptcl-10k-jets-finetune-1p
  namespace: cms-ml
  labels: { jobgroup: jjepa-job }
spec:
  completions: 5
  parallelism: 5
  completionMode: Indexed
  backoffLimit: 5
  backoffLimitPerIndex: 3 
  template:
    spec:
      restartPolicy: Never
      tolerations:
        - key: "nautilus.io/hardware"
          operator: "Equal"
          value: "gpu"
          effect: "NoSchedule"
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: kubernetes.io/hostname
                operator: NotIn
                values:
                  - ry-gpu-15.sdsc.optiputer.net
                  - gpn-fiona-mizzou-7.rnet.missouri.edu
                  - prp-gpu-3.t2.ucsd.edu
      initContainers:
      - name: init-clone-repo
        image: alpine/git
        command: ["/bin/sh","-c"]
        args:
        - |
          git clone --single-branch --branch ptcl_alan https://github.com/alanx1234/J-JEPA.git /opt/repo/J-JEPA &&
          chown -R 1000:1000 /opt/repo
        resources:
          requests: { cpu: "1", memory: 1Gi, ephemeral-storage: "1Gi" }
          limits:   { cpu: "1", memory: 1Gi,  ephemeral-storage: "4Gi" }
        volumeMounts:
        - { name: git-repo, mountPath: /opt/repo }
      containers:
      - name: runner
        image: gitlab-registry.nrp-nautilus.io/jmduarte/hbb_interaction_network:latest
        env:
        - { name: PYTHONPATH, value: "/opt/repo/J-JEPA" }
        - { name: TORCH_CUDA_ALLOC_CONF, value: "max_split_size_mb:128" }
        - name: POD_NAME
          valueFrom: { fieldRef: { fieldPath: metadata.name } }
        command: ["/bin/bash","-lc"]
        args:
        - |
          set -euo pipefail
          cd /opt/repo/J-JEPA
          pip install -e .

          python -u -m src.evaluation.finetune_ptcl \
            --option-file /config/ParT_B_amp_1p.json \
            --train-dataset-path /j-jepa-vol/J-JEPA/data/top/train/ \
            --val-dataset-path   /j-jepa-vol/J-JEPA/data/top/val/ \
            --out-dir /j-jepa-vol/J-JEPA/model_performances/top/ptcl/10k/finetune/1% \
            --load-jjepa-path /j-jepa-vol/J-JEPA/models/JetClass/ptcl/1%/best_model.pth \
            --batch-size 128 --sum 0 --flatten 1 --cls 0 --finetune 1 \
            --n-epoch 300 --num-samples 10000 \
            --from-checkpoint 0
        resources:
          requests: { cpu: "4", memory: 64Gi, nvidia.com/gpu: 1, ephemeral-storage: "1Gi" }
          limits:   { cpu: "4", memory: 64Gi, nvidia.com/gpu: 1, ephemeral-storage: "16Gi" }
        volumeMounts:
        - { name: git-repo,   mountPath: /opt/repo }
        - { name: j-jepa-vol, mountPath: /j-jepa-vol }
        - { name: config,     mountPath: /config, readOnly: true }
      volumes:
      - { name: git-repo, emptyDir: {} }
      - { name: j-jepa-vol, persistentVolumeClaim: { claimName: j-jepa-vol } }
      - { name: config,   configMap: { name: ptcl-options-amp-1p } }
